{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G9V1ZOu0Ys1"
      },
      "outputs": [],
      "source": [
        "import numpy as np               # To handle numbers, arrays, and math\n",
        "import matplotlib.pyplot as plt  # To plot graphs (reward over time)\n",
        "\n",
        "\n",
        "n_arms = 2  # We have 2 different promos (A and B)\n",
        "d = 3       # Each user has 3 features let's take  age, gender and clicked for ex\n",
        "steps = 200  # We'll simulate 200 users (or 200 rounds)\n",
        "\n",
        "#behind the scenes (what kind of user likes each promo)\n",
        "#irl with datasets it's different we don't invent true weights\n",
        "true_weights = [\n",
        "    np.array([0.2, 0.4, 0.1]),  # The second feature influences promo A the most\n",
        "    np.array([0.5, 0.1, 0.3])   #The first feature influences promo B the most\n",
        "]\n",
        "\n",
        "alpha = 0.1  # This controls how much we explore new options higher = more exploration\n",
        "\n",
        "\n",
        "\n",
        "# For each promo, we track 2 things:\n",
        "#A is a d x d identity matrix, it's like a memory of all users who saw this promo\n",
        "#b is a d x 1 vector to store rewards for each feature\n",
        "A = [np.identity(d) for _ in range(n_arms)]  #one identity matrix for each arm. A is the memory of all users shown this promo\n",
        "b = [np.zeros((d, 1)) for _ in range(n_arms)]  #  one reward vector for each arm b is your memory of all users who clicked\n",
        "\n",
        "# To track how well the agent is doing\n",
        "total_rewards = 0\n",
        "average_rewards = []\n",
        "\n",
        "# simulate users coming in one by one\n",
        "\n",
        "for step in range(steps):\n",
        "    # Create a random user with 3 features\n",
        "    context = np.random.rand(d, 1)\n",
        "\n",
        "    p = []  # This will store the UCB score for each arm\n",
        "\n",
        "    for a in range(n_arms):\n",
        "        # Estimate theta aka the weights for this arm\n",
        "        A_inv = np.linalg.inv(A[a])  # Invert the matrix A (needed for formula)\n",
        "        theta = A_inv @ b[a]         # Multiply A^-1 with b to get estimated weights (its from linear regression math gives the estimated weight for each feature) helps you estimate:\n",
        "#“What kinds of people tend to click this promo?”\n",
        "\n",
        "        # Compute the UCB score:\n",
        "        # predicted reward + exploration bonus\n",
        "        mean = (theta.T @ context)[0][0]  # Estimated reward (dot product)\n",
        "        bonus = alpha * np.sqrt((context.T @ A_inv @ context)[0][0])  # Uncertainty\n",
        "        ucb = mean + bonus\n",
        "        p.append(ucb)  # Save this arm's UCB score\n",
        "\n",
        "    # Choose the arm with the highest UCB score\n",
        "    action = np.argmax(p)\n",
        "\n",
        "    # Simulate the real reward based on true weights (adds randomness)\n",
        "    true_prob = context.T @ true_weights[action].reshape(-1, 1)  # The true click probability\n",
        "    reward = 1 if np.random.rand() < true_prob else 0  # Click (1) or not (0)\n",
        "\n",
        "    # Update A and b for the selected arm\n",
        "    A[action] += context @ context.T         # Multiply the vector context by its transpose to make a square matrix (context (3x1) @ context.T (1x3) = a 3x3 matrix)\n",
        "    b[action] += reward * context            # b = b + reward * x\n",
        "\n",
        "    # Track performance\n",
        "    total_rewards += reward\n",
        "    average_rewards.append(total_rewards / (step + 1))\n",
        "\n",
        "\n",
        "print(\"Total reward collected:\", total_rewards)  # How many clicks we got in total\n",
        "print(\"Average reward:\", total_rewards / steps)  # Average clicks per user\n",
        "\n",
        "# Plot the learning progress\n",
        "plt.plot(average_rewards)\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Average Reward\")\n",
        "plt.title(\"Contextual Bandit with LinUCB\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A:\n",
        "each time we're adding context @ context.T to one of the matrices of A and each context @ context.T is a matrix that shows how important each feature and feature combination is for this one user."
      ],
      "metadata": {
        "id": "K4zNIQOmAqHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b:\n",
        "if people who are female (feature 2) tend to click on Promo A,\n",
        "the second value of b[0] will grow bigger over time.\n",
        "In the simulation I'm running now, the code pretends to know whether the user clicked because we invented the “truth” using true_weights and np.random.rand()\n",
        "\n",
        "Each time a promo is shown and gets a click, we update b[action] like this:\n",
        "\n",
        "b[action] += reward * context\n",
        "\n",
        "reward is either 1 (clicked) or 0\n",
        "so we either remember their feature or not\n",
        "it's a cumulative reward per feature for this promo"
      ],
      "metadata": {
        "id": "ePK6eOD8DhXY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ciWOqetUDfAH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}